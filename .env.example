# Copy this file to .env and add your API keys

# ===== LLM Configuration (Choose One) =====
# For FREE tier: Use Gemini (recommended)
LLM_METHOD=gemini
GOOGLE_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-2.5-flash

# For paid tier: Use Claude (requires API credits)
# LLM_METHOD=claude
# ANTHROPIC_API_KEY=your_api_key_here

# ===== Transcription Configuration (Choose One) =====
# Option 1: Groq API - ULTRA-FAST (RECOMMENDED for speed)
# FREE: 14,400 requests/day, uses Whisper on powerful GPUs
# Get API key: https://console.groq.com/keys
# TRANSCRIPTION_METHOD=groq
# GROQ_API_KEY=your_groq_api_key_here

# Option 2: Local Whisper - SLOW but FREE and unlimited
TRANSCRIPTION_METHOD=local
WHISPER_MODEL=tiny  # Options: tiny (fastest), base, small, medium, large (slowest)

# Option 3: OpenAI Whisper API - Fast but PAID ($0.006/min)
# TRANSCRIPTION_METHOD=openai
# OPENAI_API_KEY=your_openai_key_here

# Option 4: Google Cloud Speech-to-Text (60 free min/month)
# TRANSCRIPTION_METHOD=google
# GOOGLE_APPLICATION_CREDENTIALS=/path/to/credentials.json

# ===== Debug Modes =====
# Enable to see audio energy levels (helps troubleshoot detection issues)
# DEBUG=true

# Enable to ONLY show transcripts (skips code generation, faster for testing)
# TRANSCRIPT_ONLY=true

# ===== Voice Activity Detection =====
# WebRTC VAD aggressiveness (1-3, where 3 is most aggressive)
# 1 = Less aggressive (may detect more non-speech as speech)
# 2 = Moderate (RECOMMENDED - good balance)
# 3 = Most aggressive (only very clear speech is detected)
VAD_AGGRESSIVENESS=2

# Legacy threshold parameters (kept for backward compatibility, not used by WebRTC VAD)
# VAD_THRESHOLD=50
# VAD_THRESHOLD_MIC=100
# VAD_THRESHOLD_SYSTEM=10

# ===== Silence Detection =====
# How long to wait (in seconds) after speech stops before transcribing
# Lower = faster response, but may cut off speech
# Higher = more complete sentences, but slower response
# Recommended: 0.5-1.5 seconds
SILENCE_TIMEOUT=0.5

# ===== Transcription Trigger Mode =====
# Controls when transcription is activated
# Options: auto, keyword, hotkey, both
# - auto: Automatic transcription based on silence detection (default)
# - keyword: Say a keyword to trigger the NEXT transcription
# - hotkey: Press a keyboard shortcut to trigger the NEXT transcription
# - both: Either keyword OR hotkey triggers the NEXT transcription
TRIGGER_MODE=auto

# Keyword to trigger transcription (only used if TRIGGER_MODE includes keyword)
# Default: "transcribe"
TRIGGER_KEYWORD=transcribe

# Hotkey to trigger transcription (only used if TRIGGER_MODE includes hotkey)
# Default: ctrl+shift+t
# Format: Use + to combine keys (e.g., ctrl+shift+t, alt+t, f9)
TRIGGER_HOTKEY=ctrl+shift+t

# ===== Audio Source Configuration =====
# Choose which audio to capture (default: both)
# Options: microphone, system, both
# - microphone: Only capture your voice (labeled as [You])
# - system: Only capture system/speaker audio (labeled as [Partner])
# - both: Capture both mic and system (RECOMMENDED for pair programming)
AUDIO_SOURCE=both

# ===== Recommended FREE Setup =====
# 1. Get free Gemini API key: https://aistudio.google.com/app/apikey
# 2. Set: LLM_METHOD=gemini
# 3. Set: GOOGLE_API_KEY=your_key
# 4. Set: TRANSCRIPTION_METHOD=local
# 5. Run: uv sync --extra local
