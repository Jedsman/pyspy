Project: Coach Mode - Capture & Analyze Screen with Gemini
Goal: Implement an end-to-end workflow where a user can capture a screenshot, combine it with a predefined prompt, send it to the Gemini model for analysis, and display the explanation in the Electron app.

Iteration 1: Backend - New WebSocket Handler for Multimodal Input (web_server.py)
Objective: Create a new WebSocket message type and handler in web_server.py that can receive a prompt and a screenshot path. Initially, this handler will only log the received data.

Task 1.1: Define a new WebSocket message type.
Decide on a clear type value for the WebSocket message (e.g., 'analyze_screenshot').
Determine the expected payload structure (e.g., {'type': 'analyze_screenshot', 'prompt': '...', 'screenshot_path': '...'}).
Task 1.2: Add a new handler in websocket_endpoint in web_server.py.
Inside the while True: await websocket.receive_text() loop, parse the incoming JSON message.
If data['type'] matches the new type (e.g., 'analyze_screenshot'), extract prompt and screenshot_path.
Initial Implementation: Simply print these values to the console for verification.
Test 1.1: Manual WebSocket Message Test.
Start web_server.py.
Use a simple WebSocket client (e.g., a Python script, Postman, or browser developer console) to send a message with the defined structure and dummy data.
Verify that web_server.py prints the prompt and screenshot_path correctly.

Revised Iteration 2: Frontend - Capture, Save, and Send
Objective: Modify the Electron app to perform the screen capture, save the image, and send the prompt and file path to the backend via WebSocket.

Task 2.1: Implement Screenshot Capture and Save in Electron.
In custom_prompts.js (or wherever the prompt logic resides), when the "Capture & Analyze Screen" prompt is clicked, use Electron's desktopCapturer or a similar module to capture the screen.
Save the captured image to a known directory (e.g., generated_code/screenshots/) with a unique filename (e.g., using a timestamp).
Task 2.2: Send the Multimodal Message.
After the file is successfully saved, get the full path to the new image file.
Construct the analyze_screenshot WebSocket message with the prompt text and the new file path.
Send this JSON message to the web_server.py WebSocket.
Test 2.1: End-to-End Frontend-to-Backend Message Test.
Start the Electron app and web_server.py.
Click the "Capture & Analyze Screen" prompt.
Select an area of the screen.
Verify that a .png file appears in the screenshots folder.
Verify that the web_server.py console prints the "Received Screenshot Analysis Request" message, including the correct prompt and the full path to the newly created image file.

Iteration 3: Backend - Integrate Gemini Call (web_server.py, new_gemini_service.py)
Objective: Modify the new WebSocket handler in web_server.py to call a function that uses gemini_mcp_client.py's gemini_cli_image with the received prompt and screenshot.

Task 3.1: Create a new Python module for Gemini interaction (e.g., gemini_service.py).
This module will encapsulate the logic for calling Gemini.
Define a function, e.g., analyze_image_with_prompt(image_path: Path, prompt_text: str) -> str.
Inside this function, import and use gemini_mcp_client.gemini_cli_image to make the actual call.
Return the Gemini model's response.
Task 3.2: Integrate gemini_service.py into web_server.py.
Import the new analyze_image_with_prompt function into web_server.py.
In the websocket_endpoint's handler for 'analyze_screenshot', call analyze_image_with_prompt with the received screenshot_path and prompt.
Initial Implementation: Print the Gemini response to the web_server.py console.
Test 3.1: Backend Gemini Integration Test.
Start web_server.py.
Send a manual WebSocket message (as in Test 1.1) with a valid screenshot_path (to an existing image file) and a test prompt.
Verify that web_server.py prints a response from Gemini to its console.
Optional: Mock gemini_mcp_client.gemini_cli_image to ensure the call is made correctly before integrating the actual Gemini API.
Iteration 4: Backend - Send Gemini Response Back to Frontend (web_server.py)
Objective: Modify the WebSocket handler in web_server.py to send the response from Gemini back to the Electron app via WebSocket.

Task 4.1: Send Gemini's response back to the client.
After receiving the response from analyze_image_with_prompt in web_server.py, construct a new WebSocket message.
Define a new message type for this (e.g., {'type': 'gemini_analysis_result', 'explanation': '...'}).
Use await websocket.send_json(message) to send this back to the client that initiated the request.
Test 4.1: Backend-to-Frontend Response Test.
Start both the Electron app and web_server.py.
Trigger the "Capture & Analyze Screen" workflow from the Electron app.
Using the browser's developer console, observe the incoming WebSocket messages.
Verify that the Electron app receives a message of type 'gemini_analysis_result' containing the Gemini explanation.
Iteration 5: Frontend - Display Gemini Response (overlay.html, new_ui_component.js)
Objective: Modify the Electron app to display the Gemini explanation received via WebSocket to the user.

Task 5.1: Create a UI element in overlay.html to display the explanation.
Add a new div or similar element in overlay.html where the Gemini explanation can be rendered. This could be a new panel, a modal, or a dedicated section.
Initially, this element can be hidden.
Task 5.2: Update overlay.html's ws.onmessage to handle gemini_analysis_result.
When a message of type 'gemini_analysis_result' is received, extract the explanation text.
Update the content of the UI element created in Task 5.1 with this explanation.
Make the UI element visible.
Test 5.1: Full End-to-End Workflow Test.
Start the Electron app and web_server.py.
Trigger the "Capture & Analyze Screen" workflow.
Verify that after the screenshot is taken and Gemini processes it, the explanation appears correctly in the Electron app's UI.
Iteration 6: Refinement and Error Handling (All relevant files)
Objective: Add robust error handling, loading indicators, and improve the user experience.

Task 6.1: Implement loading indicators.
In the Electron app, display a "Analyzing..." or "Waiting for Gemini..." message/spinner after sending the multimodal request and hide it when the response is received.
Task 6.2: Add error handling for Gemini API calls.
In gemini_service.py, add try-except blocks around the Gemini call to catch potential API errors (e.g., network issues, invalid API key, rate limits).
Return a structured error message or raise a custom exception.
Task 6.3: Handle errors in web_server.py.
Catch exceptions from gemini_service.py and send an appropriate error message back to the Electron app via WebSocket.
Task 6.4: Display error messages in the Electron app.
In overlay.html, update the UI to display user-friendly error messages if something goes wrong during the process.
Task 6.5: Clean up temporary screenshot files.
Consider if the saved screenshot files should be temporary and deleted after Gemini processing, or if they should persist. Implement cleanup logic if necessary.
Test 6.1: Error Simulation Test.
Simulate a Gemini API failure (e.g., by temporarily invalidating the API key or introducing a deliberate error in gemini_service.py).
Verify that the Electron app displays an appropriate error message to the user.
Test 6.2: User Experience Test.
Perform the full workflow multiple times, observing the loading states and overall responsiveness.


In the Electron app, in coach mode,I want a new option for continous transcribing. I want the interviewer speech to be captured and listed in a new window. I want the transcribed speech seperated into boxes by pauses in the speech. Each box should have a button to send the transcript to gemini for a response. Each box should also have a tick box, so that the current box and selected boxes are all sent at once. Once sent, the tick boxes should be reset